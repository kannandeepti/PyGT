{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from io import StringIO\n",
    "import time,os, importlib\n",
    "from tqdm import tqdm\n",
    "np.set_printoptions(linewidth=160)\n",
    "import lib.ktn_io as kio\n",
    "import lib.gt_tools as gt\n",
    "from scipy.sparse import save_npz,load_npz, diags, eye, csr_matrix,bmat,find\n",
    "from scipy.sparse.linalg import eigs,inv,spsolve\n",
    "from scipy.sparse.csgraph import connected_components\n",
    "import scipy as sp\n",
    "import scipy.linalg as spla\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib.colors import LogNorm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 50/767 [00:00<00:00, 740.31it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N,N_TS: 4000 2653\n",
      "GT regularization removing 767 states:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "casting to csr_matrix\n",
      "GT done, 0 rescans due to LinAlgError\n",
      "29649191.509970684\n",
      "(133, 133) (133,)\n",
      "\n",
      "\tN_states: 900 N_transitions: 2284\n",
      "\n",
      "\t5 oct STATES <-> 128 ico STATES\n",
      "\n",
      "\tbeta: 6.666666666666667 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_path = \"KTN_data/LJ38/4k\"\n",
    "\n",
    "beta = 1.0/0.15\n",
    "\n",
    "Nmax = None\n",
    "\n",
    "B, K, D, N, u, s, Emin, index_sel = kio.load_mat(path=data_path,beta=beta,Emax=None,Nmax=Nmax,screen=False)\n",
    "D = np.ravel(K.sum(axis=0))\n",
    "BF = beta*u-s\n",
    "\n",
    "BF -= BF.min()\n",
    "\n",
    "A_states,B_states = kio.load_AB(data_path,index_sel)\n",
    "\n",
    "basins = B_states + A_states\n",
    "\n",
    "inter_region = ~basins\n",
    "\n",
    "names = [\"oct\",\"ico\"]\n",
    "\n",
    "rB,rD,GT_Q,rN,retry = gt.gt_seq(N=N,rm_reg=inter_region,B=B.copy(),D=D.copy(),trmb=10,retK=True,Ndense=50,screen=True)\n",
    "\n",
    "r_A_states = A_states[~inter_region]\n",
    "r_B_states = B_states[~inter_region]\n",
    "r_BF = BF[~inter_region]\n",
    "\n",
    "tau = np.zeros(2)\n",
    "rho = np.exp(-r_BF) * r_B_states / (np.exp(-r_BF) * r_B_states).sum()\n",
    "x = spsolve(GT_Q[:,~r_A_states][~r_A_states,:],rho[~r_A_states])\n",
    "print(x.sum())\n",
    "\n",
    "#GT_Q = (1-rB)@diags(rD)\n",
    "# iGT_Q = \n",
    "\n",
    "tau = np.zeros(2)\n",
    "rho = np.exp(-r_BF) * r_B_states / (np.exp(-r_BF) * r_B_states).sum()\n",
    "x = spsolve(eye((~r_A_states).sum())-rB[:,~r_A_states][~r_A_states,:],rho[~r_A_states])\n",
    "tau_AB = (diags(1.0/rD[~r_A_states])@x).sum()\n",
    "       \n",
    "       \n",
    "\n",
    "\n",
    "print(GT_Q.shape,r_B_states.shape)\n",
    "\n",
    "print(\"\\n\\tN_states:\",N,\"N_transitions:\",K.data.size)\n",
    "print(\"\\n\\t%d %s STATES <-> %d %s STATES\" % (A_states.sum(),names[0],B_states.sum(),names[1]))\n",
    "print(\"\\n\\tbeta:\",beta,\"\\n\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 100/767 [00:00<00:01, 527.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900, 900) 900\n",
      "GT regularization removing 767 states:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "casting to csr_matrix\n",
      "GT done, 0 rescans due to LinAlgError\n",
      "(133, 133) (900, 900)\n",
      "0.9980877904580229\n"
     ]
    }
   ],
   "source": [
    "print(B.shape,N)\n",
    "rBB,rDD,iG,rN,succ = gt.gt_seq(N=N,rm_reg=inter_region,B=B.copy(),DD=csr_matrix(diags(1.0/D)),trmb=10,retK=True,Ndense=50,screen=True)\n",
    "\n",
    "print(rBB.shape,rDD.shape)\n",
    "\n",
    "x = spsolve(iG[:,~r_A_states][~r_A_states,:],rho[~r_A_states])\n",
    "\n",
    "print((rDD[:,~r_A_states]@x).sum()/tau_AB)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# remove all single states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Q = diags(D)-B@diags(D)\n",
    "\n",
    "oB=B.copy()\n",
    "oB.data[oB.data<1.0] = 0.0\n",
    "oB.eliminate_zeros()\n",
    "\n",
    "rm_reg = np.zeros(N,bool)\n",
    "#rm_reg[find(oB)[1]] = True \n",
    "r_B,r_D,GT_Q,r_N,retries = gt.gt_seq(N=N,rm_reg=rm_reg,B=B,D=D,trmb=50,retK=True,Ndense=50,screen=True)\n",
    "\n",
    "r_A_states = A_states[~rm_reg]\n",
    "r_B_states = B_states[~rm_reg]\n",
    "r_BF = BF[~rm_reg]\n",
    "\n",
    "\n",
    "find_time = np.ones(r_N,bool)\n",
    "find_time[r_B_states] = False\n",
    "tau_b = np.zeros(find_time.sum())\n",
    "\n",
    "\n",
    "\n",
    "GT_QB = GT_Q[:,~r_B_states][~r_B_states,:]\n",
    "GT_QA = GT_Q[:,~r_A_states][~r_A_states,:]\n",
    "\n",
    "rho_AnB = (np.exp(-r_BF) * r_A_states)[~r_B_states]\n",
    "rho_AnB /= rho_AnB.sum()\n",
    "rho_BnA = (np.exp(-r_BF) * r_B_states)[~r_A_states]\n",
    "rho_BnA /= rho_BnA.sum()\n",
    "\n",
    "taus = np.zeros((r_N,4))\n",
    "\n",
    "for i,ii in tqdm(enumerate(np.arange(r_N)[~r_B_states]),total=(~r_B_states).sum()):\n",
    "    select = np.arange((~r_B_states).sum())==i\n",
    "    \n",
    "    taus[ii][0] = spsolve(GT_QB,select).sum() # time to B\n",
    "    \n",
    "    # tau = k_u. Q^-2 rho\n",
    "    GT_QI = GT_QB[~select,:][:,~select]\n",
    "    ku = GT_QB[select,:][:,~select]\n",
    "    x = spsolve(GT_QI,rho_AnB[~select])\n",
    "    y = spsolve(GT_QI,x)\n",
    "    taus[ii][1] = -ku@y\n",
    "    \n",
    "\n",
    "for i,ii in tqdm(enumerate(np.arange(r_N)[~r_A_states]),total=(~r_A_states).sum()):\n",
    "    \n",
    "    select = np.arange((~r_A_states).sum())==i\n",
    "    \n",
    "    taus[ii][2] = spsolve(GT_QA,select).sum() # time to B\n",
    "    \n",
    "    # tau = k_u. Q^-2 rho\n",
    "    GT_QI = GT_QA[~select,:][:,~select]\n",
    "    ku = GT_QA[select,:][:,~select]\n",
    "    x = spsolve(GT_QI,rho_BnA[~select])\n",
    "    y = spsolve(GT_QI,x)\n",
    "    taus[ii][3] = -ku@y\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_AB = np.zeros(4)\n",
    "rho = np.exp(-r_BF) * r_A_states\n",
    "rho /= rho.sum()\n",
    "x = spla.solve(GT_Q[:,~r_B_states][~r_B_states,:].todense(),rho[~r_B_states])\n",
    "y = spla.solve(GT_Q[:,~r_B_states][~r_B_states,:].todense(),x)\n",
    "tau_AB[2] = x.sum()\n",
    "tau_AB[3] = y.sum()\n",
    "\n",
    "print(tau_AB[-2:])\n",
    "rho = np.exp(-r_BF) * r_B_states\n",
    "rho /= rho.sum()\n",
    "x = spla.solve(GT_Q[:,~r_A_states][~r_A_states,:].todense(),rho[~r_A_states])\n",
    "y = spla.solve(GT_Q[:,~r_A_states][~r_A_states,:].todense(),x)\n",
    "\n",
    "tau_AB[0] = x.sum()\n",
    "tau_AB[1] = y.sum()\n",
    "\n",
    "print(tau_AB[:2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\"\"\"\n",
    "P(first i at t) = exp(-Q)\n",
    "\n",
    "B_AI G_I B_IB\n",
    "\n",
    "\\sum_p \\sum_i P^p_i+1i tau_i = \\langle\\tau_i\\rangle N_i\n",
    "\n",
    "\\sum_p \\sum_ij tau_itau_j P^p_i+1i)= \\sum_p (\\sum_i \\tau_i\\tau_j[(G-1)]_ij P_i + \\sum_j \\tau (G-1)\\tau P_j + \\sum_i \\tau^2_i\n",
    "\n",
    "\n",
    "GAUSS-JORDAN ELIMINATION METHOD\n",
    "\n",
    "\\langle\\tau_i\\rangle N_i\n",
    "\n",
    "P(in j m after i) = [B^m]_ji\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "pi = np.exp(-r_BF[Is]) / np.exp(-r_BF[Is]).sum()\n",
    "print(taus[Is,2]@pi / 1.0e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6),dpi=120)\n",
    "Is = ~r_A_states+~r_B_states\n",
    "\n",
    "pi = np.exp(-r_BF[Is]) / np.exp(-r_BF).sum()\n",
    "\n",
    "\n",
    "plt.semilogy(np.arange(r_N)[~r_B_states],taus[~r_B_states,1]+taus[~r_B_states,0],'C0o')\n",
    "plt.semilogy(np.arange(r_N)[~r_A_states],taus[~r_A_states,3]+taus[~r_A_states,2],'C1s')\n",
    "plt.semilogy(np.arange(r_N)[r_B_states],taus[r_B_states,-2:].sum(axis=1),'rs',markersize=10)\n",
    "plt.semilogy(np.arange(r_N)[r_A_states],taus[r_A_states,:2].sum(axis=1),'bo',markersize=10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#plt.semilogy(1.0/tau_b[r_A_states[~r_B_states]],'D')\n",
    "plt.semilogy(np.arange(r_N),np.ones(r_N)*tau_AB[1],'k--')\n",
    "plt.semilogy(np.arange(r_N),np.ones(r_N)*tau_AB[0],'k--')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rBB = r_B.copy()[~r_B_states,:][:,~r_B_states]\n",
    "fi = find(rBB) # i,j,data\n",
    "nd = np.zeros(fi[2].size)\n",
    "nd = taus[~r_B_states][fi[0],:2].sum(axis=1)/taus[~r_B_states][fi[1],:2].sum(axis=1)\n",
    "\n",
    "time_to_M = csr_matrix((nd,(fi[0],fi[1])),shape=(tau_b.size,tau_b.size))\n",
    "\n",
    "rat = 1.1\n",
    "time_to_M -= diags(time_to_M.diagonal())\n",
    "time_to_M.data[time_to_M.data<1.0/rat] = 0.0\n",
    "time_to_M.data[time_to_M.data>rat] = 0.0\n",
    "time_to_M.eliminate_zeros()\n",
    "\n",
    "nc,cc = connected_components(time_to_M)\n",
    "print(np.bincount(cc),nc)\n",
    "\n",
    "fig = plt.figure(figsize=(8,8),dpi=100)\n",
    "#ax = fig.add_subplot(111)\n",
    "#ax.matshow(time_to_M.todense())#,cmap)='hot_r')\n",
    "plt.spy(time_to_M,markersize=0.3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- calculate time to target for whole system - one large task but O(N) and can be arbitrarily good\n",
    "- group according to uniformity of time and connection then make threshold on ratio\n",
    "- can we be variational about this? Can we produce an error bound under this criteria?\n",
    "# This is the only thing really worth pushing to lower T for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = diags(D)-B@diags(D)\n",
    "\n",
    "rho = np.exp(-BF) * A_states\n",
    "rho /= rho.sum()\n",
    "\n",
    "ftau=[0.,0.]\n",
    "ftau[0] = spsolve(Q[:,~B_states][~B_states,:],rho[~B_states]).sum()\n",
    "\n",
    "rho = np.exp(-BF) * B_states\n",
    "rho /= rho.sum()\n",
    "ftau[1] = spsolve(Q[:,~A_states][~A_states,:],rho[~A_states]).sum()\n",
    "\n",
    "\n",
    "oB=B.copy()\n",
    "oB.data[oB.data<1.0] = 0.0\n",
    "oB.eliminate_zeros()\n",
    "\n",
    "rm_reg = np.zeros(N,bool)\n",
    "rm_reg[find(oB)[1]] = True \n",
    "r_B,r_D,GT_Q,r_N,retries = gt.gt_seq(N=N,rm_reg=rm_reg,B=B,D=D,trmb=10,retK=True,Ndense=50,screen=True)\n",
    "\n",
    "r_A_states = A_states[~rm_reg]\n",
    "r_B_states = B_states[~rm_reg]\n",
    "r_BF = BF[~rm_reg]\n",
    "print(GT_Q.shape,r_B_states.shape)\n",
    "\n",
    "\n",
    "rho = np.exp(-r_BF) * r_A_states\n",
    "rho /= rho.sum()\n",
    "print(\"tau:\",spsolve(GT_Q[:,~r_B_states][~r_B_states,:],rho[~r_B_states]).sum()/ftau[0],end=\" \")\n",
    "rho = np.exp(-r_BF) * r_B_states\n",
    "rho /= rho.sum()\n",
    "print(\"tau:\",spsolve(GT_Q[:,~r_A_states][~r_A_states,:],rho[~r_A_states]).sum()/ftau[1],end=\" \")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Kemeny constant for nonabsorbing chain gives a mixing time. For an abosrbing chain it thus gives mixing time conditional on not absorbing.\n",
    "- If Kemeny/tau is small, we thus mix before exit\n",
    "\n",
    "- Recursive clustering\n",
    "\n",
    "- define max size\n",
    "\n",
    "- Local Kemeny constant for basin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bp_regroup(_B,_D,_BF,thresh=0.5,fs=None,dogt=False):\n",
    "    lBF = _BF.copy()\n",
    "    T = _B.copy()\n",
    "    T = _B.minimum(_B.transpose())\n",
    "    T = T@diags(T.indptr[1:]-T.indptr[:-1])\n",
    "    T.data[T.data<thresh] = 0.0\n",
    "    #T = T.minimum(T.transpose())\n",
    "    T.eliminate_zeros()\n",
    "    cc = connected_components(T)[1]\n",
    "    if dogt:\n",
    "        return cc_gt(_B,_D,_BF,cc,fs)\n",
    "    else:\n",
    "        pop = np.bincount(cc)\n",
    "        print(pop.size,pop.mean(),pop.max())\n",
    "    \n",
    "def fe_regroup(_B,_D,_BF,thresh=0.5,fs=None,dogt=False):\n",
    "    \n",
    "    T = _B.copy()@diags(_D.copy())\n",
    "    T = T.minimum(T.transpose())\n",
    "    #T = T@diags(T.indptr[1:]-T.indptr[:-1])\n",
    "    T.data[T.data<np.exp(-thresh)] = 0.0\n",
    "    #T = T.minimum(T.transpose())\n",
    "    T.eliminate_zeros()\n",
    "    cc = connected_components(T)[1]\n",
    "    if dogt:\n",
    "        return cc_gt(_B,_D,_BF,cc,fs)\n",
    "    else:\n",
    "        pop = np.bincount(cc)\n",
    "        print(pop.size,pop.mean(),pop.max())\n",
    "    \n",
    "    \n",
    "def cc_gt(_B,_D,_BF,_cc,_fs):\n",
    "    lBF = _BF.copy()\n",
    "    rm_reg = np.zeros(_BF.size,bool)\n",
    "    \n",
    "    select = np.bincount(_cc)>1\n",
    "    if not _fs is None:\n",
    "        for i in range(select.size):\n",
    "            select[i] *= (((_cc==i)*_fs).sum()==0)\n",
    "    \n",
    "    for i in select.nonzero()[0]:\n",
    "        mbf = np.ones(_BF.size)*_BF.max()\n",
    "        mbf[_cc==i] = lBF[_cc==i]\n",
    "        rm_reg += _cc==i\n",
    "        rm_reg[mbf.argmin()] = False\n",
    "        lBF[mbf.argmin()] = -np.log(np.exp(_BF[_cc==i]).sum())\n",
    "    rm_reg = rm_reg.astype(bool)\n",
    "    lB,lD,lN,ret = gt.gt_seq(N=_BF.size,rm_reg=rm_reg,B=_B,D=_D,trmb=3,retK=False,Ndense=50,screen=False)\n",
    "    \n",
    "    \n",
    "    return lB,lD,lN,lBF[~rm_reg],rm_reg\n",
    "\n",
    "def kemeny_regroup(_Q,thresh=1.0):\n",
    "    T = _Q.minimum(_Q.transpose())\n",
    "    T.data[T.data<np.exp(-thresh)] = 0.0\n",
    "    T.eliminate_zeros()\n",
    "    nc,cc = connected_components(T)    \n",
    "    pop = np.bincount(cc)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ABS = r_A_states + r_B_states\n",
    "for thresh in np.logspace(-10,-1,10):#linspace(1.0,18.0,17):\n",
    "    print(thresh,end=\": \")\n",
    "    bp_regroup(r_B,r_D,r_BF,thresh=thresh,fs=ABS)\n",
    "\n",
    "print(\"------------\")\n",
    "\n",
    "for thresh in np.linspace(1.0,18.0,17):\n",
    "    print(thresh,end=\": \")\n",
    "    fe_regroup(r_B,r_D,r_BF,thresh=thresh,fs=ABS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(-np.log((B@diags(D)).data).mean())\n",
    "\n",
    "\n",
    "Q = diags(D)-B@diags(D)\n",
    "\n",
    "rho = np.exp(-BF) * A_states\n",
    "rho /= rho.sum()\n",
    "\n",
    "ftau=[0.,0.]\n",
    "ftau[0] = spsolve(Q[:,~B_states][~B_states,:],rho[~B_states]).sum()\n",
    "\n",
    "rho = np.exp(-BF) * B_states\n",
    "rho /= rho.sum()\n",
    "ftau[1] = spsolve(Q[:,~A_states][~A_states,:],rho[~A_states]).sum()\n",
    "\n",
    "ABS = A_states.copy()+B_states.copy()\n",
    "\n",
    "for thresh in np.linspace(.0,18.0,17):\n",
    "    lBDNF = fe_regroup(B,D,BF,thresh=thresh,fs=ABS)\n",
    "    print(thresh,lBDNF[0].shape,end=\" \")\n",
    "    r_A_states = A_states[~lBDNF[-1]]\n",
    "    r_B_states = B_states[~lBDNF[-1]]\n",
    "\n",
    "\n",
    "    rho = np.exp(-lBDNF[-2]) * r_A_states\n",
    "    rho /= rho.sum()\n",
    "    r_Q = (eye(lBDNF[1].size)-lBDNF[0])@diags(lBDNF[1])\n",
    "    print(\"tau:\",spsolve(r_Q[:,~r_B_states][~r_B_states,:],rho[~r_B_states]).sum()/ftau[0],end=\" \")\n",
    "    rho = np.exp(-lBDNF[-2]) * r_B_states\n",
    "    rho /= rho.sum()\n",
    "    r_Q = (eye(lBDNF[1].size)-lBDNF[0])@diags(lBDNF[1])\n",
    "    print(\"tau:\",spsolve(r_Q[:,~r_A_states][~r_A_states,:],rho[~r_A_states]).sum()/ftau[1],\"\\n\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def split_and_connect(_T,thresh=1.0,min_block=10):\n",
    "    T = _T.copy()\n",
    "    T = T.maximum(T.transpose())\n",
    "    T.data[T.data>thresh] = 0.0\n",
    "    T.eliminate_zeros()\n",
    "    nc,cc = connected_components(T)\n",
    "    \n",
    "    pop = np.bincount(cc)\n",
    "    \n",
    "    cid = np.arange(nc)[pop>=min_block]\n",
    "    cid = cid[pop[pop>=min_block].argsort()[::-1]]        \n",
    "    cl = np.r_[[(cc == pc) for pc in cid]]\n",
    "    return cl,np.ones(T.shape[0],bool)-cl.sum(axis=0)\n",
    "    \n",
    "\n",
    "def recursive_cluster(_M,min_block=10,max_block=150,levels=30,screen=True):\n",
    "    levels+=levels%2\n",
    "    # find data range:\n",
    "    \n",
    "    M = _M.copy().minimum(_M.copy())\n",
    "    \n",
    "    M.data[M.data<0.0] = 0.0\n",
    "    M.eliminate_zeros()\n",
    "    \n",
    "    M.data = -np.log(M.data)\n",
    "    \n",
    "    M=M.maximum(M.transpose())\n",
    "    \n",
    "    thlv = np.percentile(M.data,np.exp(np.linspace(np.log(1),np.log(99),levels)))\n",
    "    \n",
    "    nc,cc = connected_components(M)\n",
    "    pop = np.bincount(cc)\n",
    "    single_nodes = np.zeros(M.shape[0],bool)\n",
    "    for i in np.arange(nc)[pop==1]:\n",
    "        single_nodes += (cc==i)\n",
    "    \n",
    "    print(\"\\n\\t%d single nodes\\n\" % single_nodes.sum())\n",
    "    \n",
    "    \n",
    "    \n",
    "    T = M.copy()\n",
    "    groups = []\n",
    "    for th in thlv[::-1]:\n",
    "        T = M.copy()\n",
    "        T.data[T.data>th] = 0.0\n",
    "        T.eliminate_zeros()\n",
    "        nc,cc = connected_components(T)\n",
    "        pop = np.bincount(cc)\n",
    "        \n",
    "        \n",
    "        clusters=set(np.arange(nc)[(pop<max_block) * (pop>=min_block)])\n",
    "        #clusters-=set(np.unique(cc[single_nodes]))\n",
    "        \n",
    "        if len(clusters)==0:\n",
    "            continue\n",
    "        \n",
    "        ## all groups less than max_block and more than min_block\n",
    "        lg = np.r_[[cc==ii for ii in clusters]].astype(bool)\n",
    "        \n",
    "        # if largest group small enough, break\n",
    "        if pop.max()<max_block:\n",
    "            break\n",
    "        \n",
    "        # else, record them with thresh\n",
    "        if lg.shape[0]>0:\n",
    "            groups.append([th,lg])\n",
    "        \n",
    "    \n",
    "    #print(\"\\n\\tgroup sizes > min_block at th=\",th,\": \",pop[pop>=min_block],\" i.e. \",len(pop[pop>=min_block]),\"groups\\n\\n\")\n",
    "    if screen:\n",
    "        print(\"\\n\\tgroup sizes > min_block at th=\",th,\": i.e. \",len(pop[pop>=min_block]),\"groups\\n\\n\")\n",
    "        print(\"\\n\\tTotal states in these groups:\",lg.sum(),\"/\",pop.sum(),\"\\n\\n\")\n",
    "        disjoint = (lg.sum(axis=0).astype(bool)==0)\n",
    "\n",
    "        print(\"\\n\\tTotal states not in these groups:\",disjoint.sum(),\"/\",pop.sum(),\"\\n\\n\")\n",
    "\n",
    "        if len(groups)>0:\n",
    "            print(\"\\n\\tGroups at other thresholds:\")\n",
    "\n",
    "        for g in groups:\n",
    "            print(\"\\n\\tth=\",g[0],\" # states:\",g[1].sum(),\" in groups disjoint to final thresh: \",\\\n",
    "                      g[1].sum(axis=1)[g[1].sum(axis=1)==(g[1]*disjoint).sum(axis=1)].sum())\n",
    "\n",
    "    return lg,single_nodes # np.r_[[cc==i for i in np.arange(nc)[pop==1]]].sum(axis=0).astype(bool)\n",
    "    \n",
    "r_N = N\n",
    "r_I_states = inter_region.copy()\n",
    "r_A_states = A_states.copy()\n",
    "r_B_states = B_states.copy()\n",
    "r_BF = BF.copy()\n",
    "r_K = K.copy()\n",
    "r_B = B.copy()\n",
    "r_D = D.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kemeny test on initial regions first\n",
    "\n",
    "- Look for exit time variance\n",
    "- Look at accuracy of eigenvalue decomposition in general - tau weight and rho weight\n",
    "- Test\n",
    "- done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_states = B_states.copy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "KAA = K.copy()[_states,:][:,_states]\n",
    "\n",
    "QfAA = (diags(D[_states])-KAA.copy()).todense()\n",
    "\n",
    "QAA = (diags(D)-K.copy()).todense()# (diags(np.ravel(KAA.sum(axis=0)).flatten())-KAA.copy()).todense()\n",
    "\n",
    "NAA = _states.sum()\n",
    "\n",
    "rho=np.exp(-BF[_states])/np.exp(-BF[_states]).sum()\n",
    "\n",
    "\"\"\"\n",
    "Gjj = [(1-Pj)K(1-Pj)]^{-1}\n",
    "sum_j pi_j Gjj = \n",
    "pi_j(1-Pj)K(1-Pj)d_i\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "NAAr = np.arange(NAA)\n",
    "\n",
    "mfpt = np.zeros(NAA)\n",
    "pbar=tqdm(total=NAA)\n",
    "for i in NAAr:\n",
    "    try:\n",
    "        vec = spla.solve(QfAA[NAAr!=i,:][:,NAAr!=i].transpose(),np.ones(NAAr.size-1))*rho[i]\n",
    "    except :\n",
    "        continue\n",
    "    mfpt[NAAr!=i] += vec\n",
    "    pbar.update(1)\n",
    "pbar.close()\n",
    "\n",
    "\n",
    "#plt.plot(mfpt[:,:,0].flatten(),\n",
    "\n",
    "plt.semilogy(mfpt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#riPI.K.rPI = (riPI.K.rPI).T\n",
    "fN = 100\n",
    "BF = np.random.uniform(size=fN)\n",
    "fQ = np.exp(-.3-np.random.uniform(size=(fN,fN)))\n",
    "fQ = np.diag(np.exp(-BF/2.0))@(fQ+fQ.T)@np.diag(np.exp(BF/2.0))\n",
    "fQ -= np.diag(fQ.sum(axis=0))\n",
    "\n",
    "kemeny = np.zeros(fN)\n",
    "\n",
    "nr = np.arange(fN)\n",
    "plt.figure(figsize=(8,6),dpi=100)\n",
    "\n",
    "for rr in [0.5,10.0]:\n",
    "    mfpt = np.zeros(fN)\n",
    "    dd = np.exp(-1.00-rr*0.001*np.random.uniform(size=fN))\n",
    "    for i in nr:\n",
    "        try:\n",
    "            vec = -spla.solve((fQ-dd)[nr!=i,:][:,nr!=i].transpose(),np.ones(nr.size-1))*np.exp(-BF[i])\n",
    "        except :\n",
    "            continue\n",
    "        mfpt[nr!=i] += vec\n",
    "    plt.plot(mfpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Just remove single nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lg,sn = recursive_cluster((B@diags(D))[inter_region,:][:,inter_region],min_block=2,max_block=100,screen=True)\n",
    "rm_reg = np.zeros(N,bool)\n",
    "#lg = recursive_cluster((B@diags(D))[inter_region,:][:,inter_region],min_block=2,max_block=100,screen=True)[0]\n",
    "\n",
    "#print(lg.shape)\n",
    "#rm_reg[inter_region] = lg.sum(axis=0).astype(bool)\n",
    "\"\"\"\n",
    "QQ = (B@diags(D)).minimum((B@diags(D)).transpose())\n",
    "QQ.eliminate_zeros()\n",
    "\n",
    "th = np.percentile(QQ.data,50)\n",
    "\n",
    "QQ.data[QQ.data<th] = 0.0\n",
    "QQ.eliminate_zeros()\n",
    "\n",
    "nc,cc=connected_components(QQ)\n",
    "print(nc,np.bincount(cc))\n",
    "\n",
    "for i in np.arange(nc):\n",
    "    print(((cc==i)@A_states).sum(),((cc==i)@B_states).sum())\n",
    "\"\"\"\n",
    "\n",
    "QQ = (B@diags(D))[inter_region,:][:,inter_region]\n",
    "nc,cc=connected_components(QQ)\n",
    "pop = np.bincount(cc)\n",
    "\n",
    "rm_reg[inter_region] = cc!=pop.argmax()\n",
    "\n",
    "#\n",
    "#r_A_states = A_states\n",
    "\n",
    "#disjoint = (lg.sum(axis=1)-lg.dot(1-A_states.astype(int)-B_states.astype(int)))==0\n",
    "#rm_reg = lg[disjoint,:].sum(axis=0).astype(bool)\n",
    "\n",
    "rB,rD,rQ,rN,retries = gt.gt_seq(N=N,rm_reg=rm_reg,B=B,D=D,trmb=10,retK=True,Ndense=10,screen=True)\n",
    "r_A_states=A_states[~rm_reg].copy()\n",
    "r_B_states=B_states[~rm_reg].copy()\n",
    "r_inter_region = inter_region[~rm_reg]\n",
    "r_BF = BF[~rm_reg]\n",
    "\n",
    "\n",
    "lg = recursive_cluster((rB@diags(rD))[r_inter_region,:][:,r_inter_region],min_block=2,max_block=100,screen=True)[0]\n",
    "rm_reg = np.zeros(rN,bool)\n",
    "#print(lg.shape)\n",
    "rm_reg[r_inter_region] = lg.sum(axis=0).astype(bool)\n",
    "GT_Q = gt.gt_seq(N=rN,rm_reg=rm_reg,B=rB,D=rD,trmb=10,retK=True,Ndense=10,screen=True)[2]\n",
    "\n",
    "r_A_states=r_A_states[~rm_reg].copy()\n",
    "r_B_states=r_B_states[~rm_reg].copy()\n",
    "r_inter_region = r_inter_region[~rm_reg]\n",
    "r_BF = r_BF[~rm_reg]\n",
    "\n",
    "\n",
    "\n",
    "print(GT_Q.shape,r_A_states.shape,rD.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig,axs = plt.subplots(4,2,figsize=(12,18),dpi=100,sharey='row')\n",
    "\n",
    "\n",
    "\n",
    "for k in range(2):\n",
    "\n",
    "    ax = axs[0,k]\n",
    "    axa = axs[1,k]\n",
    "    sax = axs[2,k]\n",
    "    eax = axs[3,k]\n",
    "    \n",
    "    \n",
    "    ni = [A_states.sum(),B_states.sum()]\n",
    "    \n",
    "    ax.set_title(r\"%s$\\to$%s (from %d$\\to$%d states)\" % (names[k],names[1-k],ni[k].sum(),ni[1-k].sum()))\n",
    "    \n",
    "    sel = [~B_states,~A_states][k]\n",
    "    r_sel = [~r_B_states,~r_A_states][k]\n",
    "\n",
    "    ni = [A_states,B_states][k]\n",
    "    r_ni = [r_A_states,r_B_states][k]\n",
    "    \n",
    "    \n",
    "    ico_D = diags(D[sel])\n",
    "    ico_K = K[sel,:][:,sel].copy()\n",
    "    ico_K.eliminate_zeros()\n",
    "    \n",
    "    \n",
    "    rho = np.exp(-BF) * [A_states,B_states][k]\n",
    "    rho = rho[sel] / rho[sel].sum()\n",
    "    \n",
    "    #rho[rho.argmax()] =  1.0\n",
    "    #rho[np.arange(rho.size)!=rho.argmax()] = 0.0\n",
    "    \n",
    "    r_rho = np.exp(-r_BF) * [r_A_states,r_B_states][k]\n",
    "    r_rho = r_rho[r_sel] / r_rho[r_sel].sum()\n",
    "    #r_rho[r_rho.argmax()] =  1.0\n",
    "    #r_rho[np.arange(r_rho.size)!=r_rho.argmax()] = 0.0\n",
    "    \n",
    "    \n",
    "    print(\"   tau:\",spsolve(ico_D-ico_K,rho).sum())\n",
    "    gt_tau = spsolve(csr_matrix(GT_Q[r_sel,:][:,r_sel]),r_rho).sum()\n",
    "    print(\"GT_tau:\",gt_tau)\n",
    "    \n",
    "\n",
    "    nu,v,w = spla.eig((ico_D-ico_K).todense(),left=True)\n",
    "    dp = np.sqrt(np.diagonal(w.T.dot(v))).real\n",
    "    v = (v.real.dot(np.diag(1.0/dp))).T\n",
    "    vm = v@rho\n",
    "    w = (w.real.dot(np.diag(1.0/dp)))\n",
    "    wm=w.sum(axis=0)\n",
    "    nu = nu.real\n",
    "    tau = (wm*vm/nu).sum()\n",
    "    \n",
    "    cond = nu.max()/nu.min()\n",
    "    \n",
    "    ta = np.logspace(-8,2.0,200)*gt_tau\n",
    "\n",
    "    \n",
    "    print(\"   tau:\",tau)\n",
    "    #p_raw = (v*w*nu)@np.exp(-np.outer(nu,ta))*tau\n",
    "    p_raw = 1.0-(wm*vm)@np.exp(-np.outer(nu,ta))\n",
    "    ax.plot(ta/tau,p_raw,'k-',label=r\"Full, N=%d, $r_\\tau$=%2.2g\" % (nu.size,1.0),lw=4)\n",
    "    \n",
    "    p_raw = (wm*nu*vm)@np.exp(-np.outer(nu,ta))*tau\n",
    "    axa.plot(ta/tau,p_raw,'k-',label=r\"Full, N=%d, $r_\\tau$=%2.2g\" % (nu.size,1.0),lw=4)\n",
    "    \n",
    "    \n",
    "    sax.plot((nu*tau)[nu.argsort()],(wm*vm)[nu.argsort()],'s',label=r\"Full, N=%d\" % nu.size)\n",
    "    eax.plot((nu*tau)[nu.argsort()],(wm*vm/nu)[nu.argsort()]/tau,'s',label=r\"Full, N=%d\" % nu.size)\n",
    "   \n",
    "    \n",
    "    itau = (wm/nu)@v\n",
    "    \n",
    "    \n",
    "    kF = (1.0/itau[rho>0.0]).dot(rho[rho>0.0])\n",
    "    \n",
    "    gt_tau = spsolve(csr_matrix(GT_Q[r_sel,:][:,r_sel]),r_rho).sum()\n",
    "    print(\"GT_tau:\",gt_tau)\n",
    "    nu,v,w = spla.eig(GT_Q[r_sel,:][:,r_sel].todense(),left=True)\n",
    "    dp = np.sqrt(np.diagonal(w.T.dot(v))).real\n",
    "    v = (v.real.dot(np.diag(1.0/dp))).T.dot(r_rho)\n",
    "    w = (w.real.dot(np.diag(1.0/dp))).sum(axis=0)\n",
    "    \n",
    "    nu = nu.real\n",
    "    tau = (v*w/nu).sum()\n",
    "    rcond = nu.max()/nu.min()\n",
    "    print(\"gt_tau, rcond:\",tau,rcond)\n",
    "    \n",
    "    r_p_raw = 1.0-(v*w)@np.exp(-np.outer(nu,ta))\n",
    "    ax.plot(ta/tau,r_p_raw,'r--',label=r\"GT, N=%d, $r_\\tau$=%2.2g\" % (nu.size,1.0),lw=4)\n",
    "    \n",
    "    r_p_raw = (v*w*nu)@np.exp(-np.outer(nu,ta))*tau\n",
    "    axa.plot(ta/tau,r_p_raw,'r--',label=r\"GT, N=%d, $r_\\tau$=%2.2g\" % (nu.size,1.0),lw=4)\n",
    "    \n",
    "    \n",
    "    sax.plot((nu*tau)[nu.argsort()],(v*w)[nu.argsort()],'o',label=r\"GT, N=%d\" % nu.size)\n",
    "    eax.plot((nu*tau)[nu.argsort()],(v*w/nu)[nu.argsort()]/tau,'o',label=r\"GT, N=%d\" % nu.size)\n",
    "    \n",
    "    ax.plot(ta/tau,1-np.exp(-ta/tau),'g-.',label=r\"$\\exp(-\\tau/\\langle\\tau\\rangle)$\",lw=4)\n",
    "    #ax.plot(ta/tau,1-np.exp(-ta*kF),'b-.',label=r\"$\\exp(-k^F\\tau)$\",lw=4)\n",
    "    \n",
    "    \n",
    "    axa.plot(ta/tau,np.exp(-ta/tau),'g-.',label=r\"$\\exp(-\\tau/\\langle\\tau\\rangle)$\",lw=4)\n",
    "    #axa.plot(ta/tau,np.exp(-ta*kF)*tau*kF,'b--',label=r\"$\\exp(-k^F\\tau)$\",lw=4)\n",
    "    \n",
    "    \n",
    "    sax.plot(np.r_[[0.99,1.0,1.01]],np.r_[[1.0e-9,1.0,1.0e-9]],'D',label=r\"$1/\\langle\\tau\\rangle$\")\n",
    "    #sax.plot(np.r_[[0.99,1.0,1.01]]*kF*tau,np.r_[[1.0e-9,1.0,1.0e-9]],'s',label=r\"$k^F$\")\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    ax.set_xlabel(r\"Time $\\tau/\\langle\\tau\\rangle$\")\n",
    "    sax.set_xlabel(r\"Frequency $\\nu\\langle\\tau\\rangle$\")\n",
    "    if k==0:\n",
    "        #axa.set_ylabel(r\"$\\langle\\tau\\rangle({\\rm d}/{\\rm d\\tau}){P}(\\tau/\\langle\\tau\\rangle)$\")\n",
    "        ax.set_ylabel(r\"CDF ${C}(\\tau/\\langle\\tau\\rangle)$\")\n",
    "        axa.set_ylabel(r\"PDF $\\langle\\tau\\rangle{P}(\\tau/\\langle\\tau\\rangle)$\")\n",
    "        sax.set_ylabel(r\"Mode Weight in $1-{C}(\\tau/\\langle\\tau\\rangle)$\")\n",
    "        eax.set_ylabel(r\"Mode Weight in $\\langle\\tau\\rangle$\")\n",
    "\n",
    "    ax.set_yscale(\"log\")\n",
    "    axa.set_yscale(\"log\")\n",
    "    sax.set_yscale(\"log\")\n",
    "    \n",
    "    eax.set_yscale(\"log\")\n",
    "    \n",
    "    ax.set_ylim(0.001,1.1)\n",
    "    axa.set_ylim(0.001,10.)\n",
    "    ax.legend()\n",
    "    eax.legend()\n",
    "    axa.legend()\n",
    "    ax.set_xscale(\"log\")\n",
    "    axa.set_xscale(\"log\")\n",
    "    sax.set_xscale(\"log\")\n",
    "    eax.set_xscale(\"log\")\n",
    "    sax.set_ylim(0.00001,2.0)\n",
    "    eax.set_ylim(0.00001,2.0)\n",
    "    sax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#----------------------------------\n",
    "\n",
    "\n",
    "for rec in range(1):\n",
    "    rm_reg = np.zeros(r_N,bool)\n",
    "    \n",
    "    # [:,r_I_states][r_I_states,:]\n",
    "    lg,sn = recursive_cluster(r_K,min_block=10,max_block=100,screen=False)\n",
    "    \n",
    "    rm_reg[r_I_states] = lg.sum(axis=0)\n",
    "    print(rm_reg.sum())\n",
    "    \n",
    "    \n",
    "    target = B_states+~r_I_states\n",
    "    plt.semilogy(spsolve((diags(r_D)-r_K)[~target,:][:,~target].transpose(),np.ones((~target).sum()))[r_I_states[~target]],'o')\n",
    "    #print(spsolve((diags(r_D)-r_K)[~A_states,:][:,~A_states].transpose(),np.ones((~A_states).sum()))[B_states[~A_states]])\n",
    "    \n",
    "    #plt.semilogy(spsolve((diags(r_D)-r_K)[~target,:][:,~target].transpose(),np.ones((~target).sum()))[rm_reg[~target]],'o')\n",
    "    \n",
    "    break\n",
    "    \n",
    "    \n",
    "    r_B,r_D,r_K,r_N,retries = gt.gt_seq(N=r_N,rm_reg=rm_reg,B=r_B,D=r_D,trmb=10,retK=True,Ndense=10,screen=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #rm_reg[r_I_states.nonzero()[0][np.r_[[ll.nonzero()[0][r_BF[r_I_states][ll].argmin()] for ll in lg]].astype(int)]] = False\n",
    "    #print(\"Removing %d states\" % rm_reg.sum())\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    work out times...\n",
    "    \"\"\"\n",
    "    \n",
    "    rm_reg = ~rm_reg\n",
    "    \n",
    "    #rm_reg[A_states+B_states] = False\n",
    "    r_B,r_D,r_K,r_N,retries = gt.gt_seq(N=r_N,rm_reg=rm_reg,B=r_B,D=r_D,trmb=10,retK=True,Ndense=10,screen=True)\n",
    "    \n",
    "    #target = (A_states+B_states)[~rm_reg]\n",
    "    \n",
    "    print(spsolve(r_K[~A_states[~rm_reg],:][:,~A_states[~rm_reg]].transpose(),np.ones((~A_states[~rm_reg]).sum()))[B_states])\n",
    "    print(spsolve(r_K[~A_states[~rm_reg],:][:,~A_states[~rm_reg]].transpose(),np.ones((~A_states[~rm_reg]).sum()))[B_states])\n",
    "    \n",
    "    \n",
    "    \n",
    "    break\n",
    "    \n",
    "    \n",
    "    \n",
    "    r_B,r_D,r_K,r_N,retries = gt.gt_seq(N=r_N,rm_reg=rm_reg,B=r_B,D=r_D,trmb=10,retK=True,Ndense=10,screen=False)\n",
    "    \n",
    "    \n",
    "    r_K = r_B@diags(r_D)\n",
    "    r_A_states = r_A_states[~rm_reg]\n",
    "    r_B_states = r_B_states[~rm_reg]\n",
    "    r_I_states = r_I_states[~rm_reg]\n",
    "    r_BF = r_BF[~rm_reg]\n",
    "\n",
    "GT_Q = diags(r_D) - r_K\n",
    "print(GT_Q.shape,r_B_states.shape,r_A_states.sum(),r_B_states.sum())\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
